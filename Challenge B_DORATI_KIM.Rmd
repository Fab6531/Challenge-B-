---
title: "Challenge B"
author: "Fabien Dorati"
date: "29 novembre 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
GitHub Link : https://github.com/Fab6531/Challenge-B-

## _**TASK 1B**_

### _Step 1 :_

We have decided to choose the random forest technique. This ML technique will predict differents values for the same characteristics using differents features (we will choose to use 5 features that will be randomly chosen) and it make the average to give us the best possible prediction.

```{r, include = FALSE, echo = FALSE}
require(tidyverse)
require(caret)
require(readxl)
require(dplyr)
require(tidyr)
require(ggplot2)
require(np)
require(randomForest)
library(gtrendsR)
library(Quandl)
library(stringr)
training <- read.csv("train.csv")
test <- read.csv("test.csv")
```
### _Step 2_ :

```{r, echo= TRUE, include=FALSE}
training2 <- select(training, -Id)
```
First, we delete the feature Id since it can't be relevant in order to determine the sale price.
```{r missing data 2, echo= FALSE, include=FALSE}
remove.vars <- training2 %>% summarise_all(.funs = funs(sum(is.na(.)))) %>% gather(key = "feature", value = "missing.observations") %>% filter(missing.observations > 100) %>% select(feature) %>% unlist

training2 <- training2 %>% select(- one_of(remove.vars))

```

```{r missing data 3, echo= FALSE, include=FALSE}

training2 %>% summarise_all(.funs = funs(sum(is.na(.)))) %>% gather(key = "feature", value = "missing.observations") %>% filter(missing.observations > 0)

training2 <- training2 %>% filter(is.na(GarageType) == FALSE, is.na(MasVnrType) == FALSE, is.na(BsmtFinType2) == FALSE, is.na(BsmtExposure) == FALSE, is.na(Electrical) == FALSE)

training2 %>% summarise_all(.funs = funs(sum(is.na(.)))) %>% gather(key = "feature", value = "missing.observations") %>% filter(missing.observations > 0)

```

```{r housing-step9-sol, echo = FALSE, include=FALSE}
cat_var <- training2 %>% summarise_all(.funs = funs(is.character(.))) %>% gather(key = "feature", value = "is.chr") %>% filter(is.chr == TRUE) %>% select(feature) %>% unlist

training2 %>% mutate_at(.cols = cat_var, .funs = as.factor)
```
Then we solve the problem of the missing values on the same way that in Challenge A. 
```{r, include=TRUE,echo=TRUE}
set.seed(1)
#We use set.seed to have every time the same model
training_RF <- randomForest(SalePrice~., data=training2, ntree=500, mtry=5, na.action = na.roughfix)
print(training_RF)
```
We use the randomForest function to create a model that we will be able to use to predict the Sale price of the houses. We choose 500 tries with 5 variables tried at each split. With this model, 85,48% of the variation of SalePrice is explained. Since it is over 80%, we can consider that it is a good model to predict. 

### _Step 3_ :

Then we create a prediction of the Sale Price with the Random Forest:
```{r, echo = TRUE, include = TRUE}
pre_train_RF <- predict(training_RF, data=test, type="response")

```
We predict the Sale Price thanks to a standard regression (using the regression founded in the solution of Challenge A :

```{r, echo = FALSE, include = TRUE}
lm_model_2 <- lm(SalePrice ~ MSZoning + LotArea + Neighborhood  + YearBuilt + OverallQual, data = training2)
summary(lm_model_2)
prediction <- data.frame(Id = test$Id, SalePrice_predict = predict(lm_model_2, test, type="response"))
```

Finally, we use the summary function to compare the two predictions : 

```{r, echo = TRUE, include = TRUE}
summary(prediction)
summary(pre_train_RF)
```
We can see that the median and the mean are slightly bigger with the ML technique than with the standard linear regression. The quartiles are equivalent but there is huge differences in the minimum and in the maximum. The minimum with the Random Forest is 92 436 dollars, that is a more realistic case than the prediction of the standard linear model (11 634 dollars).  


## _**TASK 2B**_ : 

### Before Starting 
Let's install packages and run them. I use np package for non parametric regression(npreg) and ggplot for plotting as usual. 

```{r, echo=FALSE, warning=FALSE}
require("np")
require("tidyverse")
```

As Challenge A, I generate 150 random samples of x and epsilon following normal distribution with mean 0 and standard deviation 1. True value for y is x^3, but assume we observe x^3 with epsilon noise, which is y here. Then, to make trainset and testset, I divide 150 random samples randomly into 120 samples for trainset and 30 samples for testset. Both of them contain randomly generated x and observed y, which is x^3+e.  

```{r - generating samples, trainset, testset, echo=TRUE, hide=TRUE}
set.seed(5)
x <- rnorm(150, mean = 0, sd = 1)
e <- rnorm(150, mean = 0, sd = 1)
y <- x^3 + e

tasktable <- cbind(x,y)

yhat <- x^3

train_idx <- sample(1:nrow(tasktable),120,replace=FALSE)
trainset <- tasktable[train_idx,] 
testset <- tasktable[-train_idx,]

trainset <- as.data.frame(trainset)
testset <- as.data.frame(testset)
```


### Question 1
I will use npreg function for non parametric regression methods.  Among these methods, I want to use local linear method with bandwidth 0.5. In this stage, I only use trainset with fixed bandwidth 0.5. I call this model ll.fit.lowflex and I predict y or estimate y with given x in my trainset. And I form xs and estimated y into a data frame predict.low 
```{r - npreg for low flex, echo=FALSE}
ll.fit.lowflex <- npreg(y~x, data= trainset, method = "ll", bws = 0.5)
summary(ll.fit.lowflex)

predict.low <- predict(object = ll.fit.lowflex, newdata=trainset)
predict.low <- data.frame(predict.low)
predict.low <- cbind(trainset[,1], predict.low)
```

### Question 2
Basically same steps are done for ll.fit.highflex, but bandwidth is different. Now flexibility is high, 0.01. 
```{r - npreg for high flex, echo=FALSE}
ll.fit.highflex <- npreg(y~x, data= trainset, method = "ll", bws = 0.01)
summary(ll.fit.highflex)

predict.high <- predict(object = ll.fit.highflex, newdata= trainset)
predict.high <- data.frame(predict.high)
predict.high <- cbind(trainset[,1], predict.high)
```

### Question 3
I want to plot 4 figures on the same plot. First, scatter point of observed y and x of trainset. Second, the black line telling the relationship between true y and x - of course this will be equation y=x^3. Closer my estimated ys are to true ys, my estimation is better. Third, the red line for ll.fit.lowflex. As we can see, the line is really smooth (Perhaps too smooth). ll.fit.lowflex is somehow strictforward in the sense of prediction, since its variance is low. However, ll.fit.lowflex does not allow enough exceptions. Therefore, bias is high. Fourth, the blue line for ll.fit.highflex. This line is rather complex (Perhaps too complex). It catches most of exceptions, but at the same time the relationship between y and x becomes too complex, because of its high variance.    

```{r - Plots based on trainset, echo=FALSE}
ggplot(mapping=aes(x=x, y=y)) + 
geom_point(mapping = aes(x=trainset[,1], y=trainset[,2])) + 
geom_line(mapping = aes(x=predict.low[,1], y=predict.low[,2]), color="red") +
geom_line(mapping = aes(x=predict.high[,1], y=predict.high[,2]), color="Blue") +
geom_line(mapping = aes(x=trainset[,1], y=trainset[,1]^3))
```

### Question 4
Comparing ll.fit.lowflex and ll.fit.highflex, ll.fit.highflex which is with lower bandwidth is more variable. It is natural that it gets lower bias, because it is flexible enough to contain exceptional ys. However, for ll.fit.lowflex, its bandwidth is too high to contain excetpional ys. Meanwhile, in the view of variance, low bandwidth is flexible, but has higher variance than high bandwidth. Here, we can see bias-variance tradeoff.   

```{r - bias for ll.fit.lowflex & ll.fit.highflex, echo=TRUE}
bias.low <- mean(predict.low[,2] - trainset[,2])  
print(bias.low) ## bias.low
bias.high <- mean(predict.high[,2] - trainset[,2])
print(bias.high) ## bias.high

variance.low <- var(predict.low[,2])
print(variance.low) ## variance.low
variance.high <- var(predict.high[,2])
print(variance.high) ## variance.high
```

### Question 5
Based on models I made with trainset data, ll.fit.lowflex and ll.fit.highflex, I want to test with my 30 samples in testset. Here, I use predict function. After getting estimated ys of testset, I combine with xs of test set. Here, I want to show 4 figures on the same plot. First, scatter points of x and y in testset. Second, the black like which is showing true relationship between true y and x of testset - of course this will be equation y=x^3. Third, the red line with predicted y or estimated y of using ll.fit.lowflex on testset x. Fourth, the blue line with predicted y or estimated y of using 11.fit.highflex on testset x.
 
```{r - Plots based on testset, echo=FALSE}

predict.low.test <- predict(ll.fit.lowflex, newdata = testset)
predict.low.test <- data.frame(predict.low.test)
predict.low.test <- cbind(testset[,1], predict.low.test)


predict.high.test <- predict(ll.fit.highflex, newdata = testset)
predict.high.test <- data.frame(predict.high.test)
predict.high.test <- cbind(testset[,1], predict.high.test)

ggplot(mapping=aes(x=x, y=y)) + 
geom_point(mapping = aes(x=testset[,1], y=testset[,2])) + 
geom_line(mapping = aes(x=predict.low.test[,1], y=predict.low.test[,2]), color="red") +
geom_line(mapping = aes(x=predict.high.test[,1], y=predict.high.test[,2]), color="Blue") +
geom_line(mapping = aes(x=testset[,1], y=testset[,1]^3))
```

Again, let's see what happens for bias and variance. ll.fit.highflex is still more variable than ll.fit.lowflex. Its variance is higher. The least biased model was ll.fit.highflex. Comparing to former bias of ll.fit.highflex on trainset, now it gets bigger bias (in absolute value).  


```{r - bias for ll.fit.lowflex & ll.fit.highflex on testset, echo=TRUE}
bias.low.test <- mean(predict.low.test[,2] - testset[,2])  
print(bias.low.test) ##bias.low.test
bias.high.test <- mean(predict.high.test[,2] - testset[,2])
print(bias.high.test) ##bias.high.test

variance.low.test <- var(predict.low.test[,2])
print(variance.low.test) ##variance.low.test
variance.high.test <- var(predict.high.test[,2])
print(variance.high.test) ##variance.high.test
```


### Question 6
I make bandwidth vector starting from 0.01 to 0.5 with step 0.001. First I make vector from 10 to 500 which is increasing by 1. Then I divide with 1000. It is exactly same. Since, 10/1000=0.01, 500/1000=0.5, 1/1000=0.001
```{r, echo=TRUE, hide=TRUE}
bandwidth <- 10:500
bandwidth <- bandwidth/1000
```

### Question 7
I want to use loop. First as a starting matrix, I make a vector with length 120. Then I put new column with 120 rows which is predicted y or estimated y with each element in bandwidth vector - so it is bandwidth starting form 0.01 to 0.5. loop keeps putting this new column to starting matrix. When the loop ends, I delete the first column which is irrelevant. I call outcome matrix lltabletrain. Its size is then 120 X 491

```{r, echo=TRUE, hide=TRUE}
lltabletrain <- matrix(0,120,1)

for (i in 1:length(bandwidth)) {
  ll.fit <- npreg(y~x, data = trainset, method='ll', bws=bandwidth[i])
  col <- predict(ll.fit, newdata = trainset)
  lltabletrain <- cbind(lltabletrain, col)
}

lltabletrain <- lltabletrain[,-1]
```

### Question 8
Again, I want to use loop function. I add new column which is MSE. As I mentioned before, each column of lltabletrain is predicted y with each bandwidth. With each column, I use MSE formulating function with mean function. As a result, I get matrix with 491 MSE coming from each bandwidth. 
```{r, echo=TRUE, hide=TRUE}
msetabletrain <- 0  

for (i in 1:ncol(lltabletrain)) {
  square.error <- (lltabletrain[,i] - trainset[,2])^2
  t <- mean(square.error) 
  msetabletrain <- cbind(msetabletrain, t)     
}

msetabletrain <- msetabletrain[,-1]
```

### Question 9
Now, I use the same two loop functions for testset. The difference is that predicted or estimated ys are based on x of testset. ll.fit model is made with trainset x and y. We put x of testset as newdata and get predicted y from this model.

```{r, echo=TRUE, hide=TRUE}
lltabletest <- matrix(0,30,1)

for (i in 1:length(bandwidth)) {
  ll.fit <- npreg(y~x, data = trainset, method='ll', bws=bandwidth[i])
  col2 <- predict(object = ll.fit, newdata=testset)
  lltabletest <- cbind(lltabletest, col2)
}

lltabletest <- lltabletest[,-1]


msetabletest <- 0  

for (i in 1:ncol(lltabletest)) {
  square.error2 <- (lltabletest[,i]-testset[,2])^2
  d <- mean(square.error2) 
  msetabletest <- cbind(msetabletest, d)     
}

msetabletest <- msetabletest[,-1]
```

### Question 10
I make two tables. First column is common and it is for bandwidth from 0.01 to 0.5. For second column, for MSEtrain, it is MSE from trainset. For MSEtest, it is from testset. On the plot, orange line is showing how MSE of on the trainset is changing according to bandwidth from 0.01 to 0.5. Blue line is showing it of testset. 

```{r - MSE & Bandwidth, echo=FALSE}
# 2.9
MSEtrain <- cbind(bandwidth, msetabletrain)
MSEtest <- cbind(bandwidth, msetabletest)

ggplot(mapping=aes(x=bandwidth, y=MSE)) + 
geom_line(mapping = aes(x=MSEtrain[,1], y=MSEtrain[,2]), color="Orange") + 
geom_line(mapping = aes(x=MSEtest[,1], y=MSEtest[,2]), color="Blue") 
```

Indeed, MSE can be decomposed into two parts. MSE = Var + Bias^2. For the trainset MSE line, When bandwidth is small, it has bigger bias but smaller variance. However, as bandwidth increases, bias gets smaller, but variance increases. If the speed of incrasing variance is faster than decreasing bias, MSE, sum of these two, will increase. 

However, it does not mean we should choose the bandwidth which is giving the least MSE on trainset. We should also consider what MSE on testset such bandwidth brings. As we can see in the plot, the least MSE on trainset is given when bandwidth 0.01. However, considering MSE on trainset, it does not give lowest MSE. It would be because its bandwidth is too low that bias is too high when it is applied to testset. 

So for higher accuracy of our model, we need to compare both MSE on trainset and MSE on testset. 



## _**TASK 3B**_ :

```{r, echo= FALSE, include=FALSE}
require("data.table")
```

### _Step 1_

We import the CNIL DATA thanks to the read.csv2 function : 
```{r, include=FALSE, echo=FALSE}
CNIL <- read.csv2("OpenCNIL_Organismes_avec_CIL_VD_20171115.csv")
#We import the File OpenCNIL using the read.csv2 function. 

```

### _Step 2_

We want to create a table with the number of organizations that has nominated a CNIL per department. First we define a variable Dep with the first two number of the "Code Postal": 
```{r, echo = TRUE, include = FALSE}
CNIL<- CNIL %>% mutate(Dep=substr(Code_Postal,1,2))
CNIL<- CNIL %>% mutate(Dep_int=as.integer(Dep))
```

We remove the potential duplicates that we could have on the data :
```{r, echo = TRUE, include = FALSE}
CNIL<-distinct(CNIL)
```

Then we create the related table: 
```{r, echo = FALSE, include = TRUE}
CNILPD <- table(CNIL$Dep_int, CNIL$TypeCIL)
CNILPD
```

### _Step 3_ :

First we import 10000 rows from the data SIREN
```{r, echo = TRUE, include = FALSE}
SIREN <- read.csv2("sirc-17804_9075_14209_201710_L_M_20171101_030132835.csv",nrows=10000)

```

In order to merge the whole database, we create a function that will merge the data by their Siren number, and we repeat it 1000 times to get the best database. Since our computers have no enough memory, we put eval = FALSE.
```{r, echo = TRUE, include = FALSE, eval = FALSE}
f <- function(SIREN, pos) merge(CNIL, SIREN, by = intersect("Ã¯..Siren", "SIREN" ))
SIREN2 <-read_csv2_chunked(file="sirc-17804_9075_14209_201710_L_M_20171101_030132835.csv", DataFrameCallback$new(f), chunk_size = 1000)
```

```{r, echo=FALSE, include=FALSE, eval = FALSE}
system.time(SIREN2 <-read_csv2_chunked(file="sirc-17804_9075_14209_201710_L_M_20171101_030132835.csv", DataFrameCallback$new(f), chunk_size = 1000))
```

Then, in order to merge the data, we want that the column have the same name, so we change the name into SIREN for the CNIL file.
```{r, echo = FALSE, include = FALSE}
names(CNIL)[names(CNIL) == 'ï..Siren'] <- 'SIREN'
```
So we make a simple merger to have an sample of what we would get with the previous function 
```{r, echo = TRUE, include = TRUE}
Merger <- merge.data.frame(CNIL, SIREN, by = 'SIREN')
```

### _Step 4_

We use the ggplot function in order to create an histogram with the number of firms on the y-axe and the size range as abscissa. 
```{r, echo = TRUE, include = TRUE}
ggplot(Merger) +
  geom_histogram(aes(TEFEN), stat="count") + 
  ylab("Number of firms") + xlab("Size range of firms")
```
